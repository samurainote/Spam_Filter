{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter: Text Classification with uci enron dataset\n",
    "### スパムメールフィルター"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-01-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://www.webdevelopersnotes.com/wp-content/uploads/gmail-spam-filter-how-it-works.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspecting the dataset データの調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, learning_curve, StratifiedShuffleSplit, GridSearchCV,\n",
    "    cross_val_score)\n",
    "\n",
    "# Improve the readability of figures\n",
    "sns.set_context('notebook', font_scale=1.4)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/akr712/Desktop/spam_filter_enron_dataset\")\n",
    "df = pd.read_table(\"SMSSpamCollection.txt\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの詳細を一通り眺める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Target    5572 non-null object\n",
      "Text      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.columns = [\"Target\", \"Text\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【メモ】\n",
    "  「スパム」のデータ量は、「スパムではないメッセージ」のデータ量に比べてかなり少ない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「スパム」と「スパムではないメッセージ」によく含まれる単語の違いをイメージできるようにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算負荷を減らすため、目的変数となる\"Target\"列をバイナリに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df[\"Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text preprocessing - 前処理 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然言語を特徴量に転換するために、数値情報に変える必要がある。   \n",
    "自然言語処理では、元データとなる文章や単語をそのまま特徴量として使おうとすると、以下のデメリットが生じる。   \n",
    "    \n",
    "・説明変数が膨大になり学習に時間がかかる  \n",
    "・過学習を起こしやすくなる    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Normalization - 単語の正規化 -    \n",
    "    \n",
    "大文字や小文字を揃える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTp7ERA8pYIVb6Afzvihd0G75GIPX4q5nAJMw3fZBaFK19IihnnBw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_exapmple = df.iloc[0][\"Text\"]\n",
    "text_exapmple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、本文とは関係がない文字列や頻出する記号や単語を排除する。  \n",
    "「メールアドレス」、「URL」、「$」、「電話番号」など。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = df[\"Text\"]\n",
    "processed = raw_text.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b',\n",
    "                                 'emailaddr')\n",
    "processed = processed.str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)',\n",
    "                                  'httpaddr')\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')    \n",
    "processed = processed.str.replace(\n",
    "    r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "    'phonenumbr')    \n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"today\"と\"today?\"を揃える\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全て小文字にする\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Stop words - ストップワードの削除 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "頻出するものの、文章の特徴を表す訳ではない単語をストップワードとして、特徴から外してしまう。   \n",
    "例としては、\"when\"や\"had\"などが含まれる。   \n",
    "基本的にはコーパスと呼ばれる各言語ごとの文脈を含んだ辞書にストップワードリストがまとめられている。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in set(stop_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Stemming - 語幹による単語の統一化 -  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "語形の変化を取り除き、同一の単語表現に変換する処理のこと。   \n",
    "例えば、「run」というクエリで検索をした場合でもrunnerやrunningなどのキーワードとマッチングさせること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "processed = processed.apply(lambda x: ' '.join(porter.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(messy_string):\n",
    "    assert(type(messy_string) == str)\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processed == raw_text.apply(preprocess_text)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(text_exapmple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature engineering - 特徴量生成 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAMAAAAxzFJiAAAA0lBMVEX////y3NsAAAC8Pjq+R0Tao6L48O/x2djz3t315eS9REDnxMToyMfr0M/qzMv139775OPAUE1ubm7n0tGnp6f/6egODQ3gzMvr6+vSv77ItrX29vacnJxYUFAUEhKtnZ3Kysp7e3uHe3qwoJ8tKSkcHByhk5LZxcRsYmLit7aDd3dhWFibjYy5qKc5NDSQg4J2a2tNRkaysrJFPz5OTk7CwsLTjIrDWFWUlJTR0dHi4uJhYWHPgH7JbWsnIyM0MC+6NjLZmpnHY2Dgr66IiIhnZ2dJ5c4kAAANLklEQVR4nO2djV+iTBDHZeQk6e52jZCgUwoVPRHBqO56016e+///pWdmQc/KLjOFEn6fS2V3ebkvw7DADlMqFSpUqFChrVNl90uhDehn5WXk17eqXGgDUm+vX8BeleWaWi60Aak1Wd5ZxPxQrsn3u9VKobWrunuPcBfZ+p0sn69yHii0jM4X05Vrv1LflBzpV009fFaolOUvGWxLbvQgq9+eFX5X1d0MtiU3Wsj3q6p+z2BbFquyswWqPjpzfvvo0HcUaRukVOf+Tx8dejVrWuuSMmfrHx36dtg5ac7UPzj0yvZAn7sKLaCnpQJ6Btpy6Jy9rVyIvTgXX9D27Ru17dBDZzG/frCAbFLErNBaOBfrO8+KBqH29q3aMujMglgxCgU6iywRW/UVL3hClhnegIqYDe5i6ABPi/gIjH8dNIu1bdC7XhjBqOfFjRVoL4LO+2AZMHpSxUzoUdHL0OvNZ0tqFNDJRegBtHTOODlggk5OI55CTx57EF4HrkFDp59cVIu/LoT6DDqbVgj/H0/F0BktXIprYuiiNvnMI3QkEYDNmOF4gcYQuu73fa4FnoNTfbtFHgRNus/6MHEMJiq4jU0CRwshcpQEOvd7PZ+bfZszB/3QwOt3WQydWX2rHyp9l2l9VxfQB16ItWbouXmGzrsAdXLsEJkwZAZAG0BRhLcfMPIuGv3sxhUafg3A1ZJzAUHX+9BsQsBxLh8C1qFm3QT6ABfdwwOFo4ci6NKYak0JmhEsd1bdTui6hy4mAIfBENoSD8GWBjCQoKNZ6Mp5s46HAlLDCldyIdB9QHc+79M1mGhaB1gLBg1gLjjIvsen0HuaFkNvIHTNxbMy1kow8rXlOpBbCn0IGjchZMJ40fGSCIuuQaRjBSfo+rSC4zEQCJ8+hd6l8g50ebuDSwtoqhnNoLdodk9PoDuidqi7+OUv5dW3FHoIjtFDTwIdF0mjzRuWhR5+xAm6AxZZetTFpn2q4KNOBBbuJa/LYujoK0wDPTTzocPQ3nuG6bOZe7GZpEHTcgR0wwdP1NpdPz5U8gjdAZcr6GVhhJib+ghPi0MyRuzLDBH6UEe3gezGZJeRqHDANvGIoOMCL4sQ+oD7VIFnUN5u4UdPnAHifjqjE7XEPToSRrh0I6k16bOVU0tnXcvA7pvlWmh1aMYambLltjRGU4plYt+F7FFzbS2ukHy0fNPqMs1t0UoMy2BMa7l0Xcq6Ykearm3Q/NPl41erhcvC2ZSkluYw8+rTJRZfzIsv+oj/ZlPUd2Gzduxvi9msczX4lZTM2sw1iv9Na6dz5BL6a9KMNS1oZeUQevYqoGegzwO9eEaahYrRAFloW8a9zI82+vDQS5XqhkdfSd+/KRtexWcb4bV5Sbe3P9NdYwG9JKlyAT1t7RTQ09ZOdVeVv1R3no/S35xyD/36Vq3V5LKc5jpzD71arqHSDYLIPfTSuYzQ0w2xKqCTqacc7VNAJ1NPOZawgF6q3KYd1lZAR1NPO2i2gI5ePe34zY8PvSopG5a08TUoO5/qhtfhdtzZ/VwhjTtZ01qXPsNDjMrt+S5tZtas1qe3P64725/px2ZpT1WT1fKvu5/fs2a1Nr39wfQf+KvngN50h+5wudbXdEtEVm9/bouDeTv0PfhxdJboWfN9+P0G6ABLUK/8kgX0X9+3hflK0I9eJrQPb3E5nWWgx8zV68rKzJcd7baUFoQ1vlkfHvqdLN/8qpUfVh5sxDXLWnKwvmgusZcDSbHai96/Cz869MptrVa6p7f/rAadKV4cELCkeAgWD8bmS2T5GLYf+oOMG/VAfawVoU9g6LpteCGI95l4BK4ewuLoXapvw/v9y7uhP8b2GPrBQfJ9eTBfOptaAvq1PH2H3krQ2QAaFNTo8iR6MQ5IjEMc45+SNIt4FFMm1/tgztpLs1mE2xHQ2XRRKzr4d0M/g/phDPCydBF3JCOcPIaLM/xJfZmTMf4YT3s6+zTV3MdfV3Hr512ged3L0/t+q70bIIqNlv6CyXDAmN1oRVE3GHsadxut0bCFDAfDSYCOKOyMfCw07TGMAs6CySSJoG74I89oBBz/dITOur1Ow2LMH477Kx1+73cvx3AlCCLHy6sRRHt//hOlP+B0D3cE9us7v0+OIZkLSR//xqnTUun3nzr82bu6+Cf0G7n2LugT0BJzHcFkDCEFbdXFzm7oDsAE0IWHMJ5AhDXh0KaQAbcO474+gsZIxGxwivNyDPB4FzyCbuA5ogldDaJwlBr0J5iG6FL24Y/4fULs410x3Td/9ujzAib09R+ciuPi9IQ+Owuurp7oXFar74GeWDrFK4503gGNwsBG6D7qgNBbug8ehVVjUTeAni0i2IV7MSEyrToFGSF0R2ddAb2H0LE6MF0IJZgES8a7rAH61V6iuOAA4AKa8e+ZTz+GvcezdQA9+eHjy6ElfPpXVb57B3TmUtwoZz3NQiunWLgAfN0DTe8QdBM5NihgXZw7Q/R7DKFzgm5BczKJ2oaA7jOCrifQe9CeDKOe7neWjexaA/SndwHIeV8+g34ym+Pw8vLyICLoJ3D8eEe83k+v1crfVocusQja7mAMnoSAXGgSQWIfQx/5DQh4E9wWgGQFhgeGI6APKADasgK6rhLQJQ3qtiegcxt6pt/SldBsxZGnaUA/Kx3GmhZF5KKfQj9Kio4myS5C6L8f9yiXgf61nDygX/XiKKR195l4KUnH5ORTRggdCDpuWiQxs0mxjIga8LAIwefUVHyI12HQLIz8DkRo7XVgXCxSEzGML/Yt1w396EmbE+hMXfkc9MTzHwH8ODs7OxoS9B9vh166K9fK18rqzzCmV6RMskw0XM1QmGZIzDAQptUVYYvMtLAaG2IDrMdK38CmphWfhKmIwhpNZmg4n1ikSbF00wYZQL+EzsHUvzyHfprUnBL0s9khsTz00pfbmqyqN1/efe/lb4xi3DknT8LmW7BZ3Xzs4t+wxtm8Txu8UWuA3kG+J9BOoP9+An2YgK0T9BIkxXHZZCnoJeWmLNfUu3XfZEToy4Xyr12rQD85mOpQTJNxX8W9lSMy5Yt56FfxbtgTPp3OuXQxdNEc0qynuP8ODkqvS7m7Vx/WfmdXWeH1W2vR+x5i7JNtxx6jHndX8GTVpENhdjxcYrOrUzi9EtDxkBCvWIn3xBmdm8ZLQCdty3NpaRXo+8cz7R2VDvf2YhdxsXdMPw6uoE2Wv7+XdCJLB8djiPZLP5J2B/8N65PjaQ+zDa9ckc5pe6AXIY3pS5n7T3106GmENFKE3ab16UIaNyzp589vm17H42wvHx/6xlWENGagIqQxA1UL6GnrHi98aVBTEdKYor6J6Dr5IdV15h166UZAT3WVBXSlnLahF9CFqadr6AV0kakvXUMvoKNu1JRXWEBHBmmnpPz40Dd+7yUVPfovfXjoxYvT0tf23E+fu+T96NC3w85Jn+fJUfHa1wxUQM9ABfQMtDboq43LWvqN9EsoL9C5EGX00gY+e56l8bVsi8wcvBj89WblBXqnjgLDb3QpaZ3hPBlXzmzv38O92OCFhHarKC/QAaIoamsTcCgtlAneY8vm8ApT5lLOlzUpL9BpWDm6F9PRKCUUhVRI0wSkjJyOFYh0Ikmw3TQJCRZM85gI6NOMI8tmBsw9dDHU2bQNhM4CiGyNSbZjM6a5luVolq0Zruk7Fvp733FtGs+LNb6jtGyJtWwBnZtB0KVESE6rgL4UdEMzNBodbYAXZwvUKACDsgmOAaQQTAviiIyQCnqckjm2AfQOkPMh6HE6NV/vQf19g6zzA11EMQaU/bXBLQTPQrAp5ZqBoIk0Qh92A+hz8CohKCIpbNMy9TY6po6ArkGkaFDX2x1rtai6/EEPw3AwhY4+nfORGO0dUnAdi6E7lEtQ96APbRZn4sWaMTB9LKBbcQSq4sNrp90CegJdhJrPoHsKch5olqVQVK4UQ+/jIRAq0BuFGpumP+ZtsExILH3SNXyNdU2r867XMuQFOoAI1hI+fcRxEkxN2K1EO4FSAk6h404IAj+GjruDCUcO1E+PfbrNKFVg4z3+JS/QbZGJmFmuobkUitsPDKbY/YCyBCJhrMDei8XwT6NAEXA49V4Ee7tvtlzJdE3GraDfknCO0H3XxuQF+ix+jiVpA0W6V/4oVWBcgY6m0oUhn80Ud9sZ+5u7u+inr1nMF29sWN/l5wIV0J8KXYzrdtfwpq6XVUB/JsbWeRt3kT4P9OIZaRYqRgNkoSK6LgttRXTdEiO8sDDlKJwslX503e4io66W5fN0NyNLpR9ddy6Xq89L72vqgtItVerQq+rCHD9fyzVZWVC+lUo7S6NUq5UXpj45V2vqzd2XXOhBlnfTW9vdDaK9Xrw7zm/lnEi9Q+iprrH84glTua6Vc6Hbc4Suprc++fqfjruSDyno01Nc3Vvc//Yq/XTHhQro6SuLHNO5VxY5pnOvLHJMFxI5pu+z3oqcqZJ+julCGeSYLpRBjulCGeSYLoQdmMyfTf4P54HrfhGYgEIAAAAASUVORK5CYII=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Tokenization - トークン化（単語分解） -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文書をトークンに分解すること。一般的にトークナイズには以下の2種類がある。   \n",
    "   \n",
    "・形態素解析   \n",
    "・N-gram   \n",
    "    \n",
    "★トークナイズの例：「東京都と神奈川県」\n",
    "\n",
    "#### 形態素解析\n",
    "東京/都/と/神奈川/県\n",
    "\n",
    "#### N-gram\n",
    "東京/京都/都と/と神/神奈/奈川/川県"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Term Frequency and Inverse Document Frequency (TF-IDF) - 重要単語評価 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Wrod Vectrization - 単語のベクトル化（次元表現）-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 36323)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_ngrams = vectorizer.fit_transform(processed)\n",
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What terms are the top predictors of spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
